"""
0G-Storage based KV-Storage implementation

Uses 0g-storage Python SDK (CachedKvClient) for storage operations.
All values are UTF-8 encoded as bytes.

Key Format: {collection_name}:{document_id}
Example: "episodic_memories:6979da5797f9041fc0aa063f"

Environment Variables Required:
- ZEROG_WALLET_KEY: Wallet private key (IMPORTANT: Keep secure!)

Concurrency Model:
- Single CachedKvClient shared across all coroutines/threads.
- SDK methods set(), get_bytes(), and commit() are all thread-safe.
- A dedicated background daemon thread (_commit_thread) wakes up every
  COMMIT_INTERVAL seconds. If _pending_count > 0, it calls cached.commit()
  (non-blocking: actual upload happens inside the SDK) and resets the counter;
  otherwise it skips the interval entirely.
- _pending_count is an _AtomicInt; increment() and get_and_reset() are each
  individually atomic, so there is no race between the writer and commit thread.
"""

import os
import random
import threading

# Fixed encryption key derived from a hardcoded seed.
# Deterministic across restarts so previously written data remains readable.
# TODO: replace with a proper key from environment variable before production.
_rng = random.Random(0x4576_724D_656D_4F53)  # seed = "EverMemOS" in hex
_ENCRYPTION_KEY: bytes = bytes(_rng.getrandbits(8) for _ in range(32))
from datetime import datetime
from typing import Optional, Dict, List, Tuple, AsyncIterator



class _AtomicInt:
    """Minimal thread-safe integer counter.

    increment() and get_and_reset() are each atomic operations.
    """

    __slots__ = ("_value", "_lock")

    def __init__(self) -> None:
        self._value: int = 0
        self._lock = threading.Lock()

    def increment(self) -> None:
        with self._lock:
            self._value += 1

    def get_and_reset(self) -> int:
        """Return current value and atomically reset to 0."""
        with self._lock:
            value, self._value = self._value, 0
            return value

    def __bool__(self) -> bool:
        return bool(self._value)

from core.observation.logger import get_logger
from core.di.decorators import component
from .kv_storage_interface import KVStorageInterface

from zg_storage import CachedKvClient, EvmClient, UploadOption

logger = get_logger(__name__)

COMMIT_INTERVAL = 20  # seconds between commit attempts


@component("zerog_kv_storage")
class ZeroGKVStorage(KVStorageInterface):
    """
    0G-Storage based KV-Storage implementation using CachedKvClient.

    put/delete: call cached.set() to stage the op (fast, in-memory).
    commit: a dedicated background thread wakes every COMMIT_INTERVAL seconds
            and calls cached.commit() only if there are pending staged ops.
    get: cached.get_bytes() reads from local cache or the KV node.
    """

    def __init__(
        self,
        kv_url: str,                    # KV node URL for reads/writes
        stream_id: str,                 # Unified stream ID for all collections
        rpc_url: str,                   # "https://evmrpc-testnet.0g.ai"
        indexer_url: str,               # Indexer URL for uploads
        flow_address: str,              # Flow contract address
        max_queue_size: int = 100,      # Internal write queue size
        max_cache_entries: int = 10000, # Local read cache size
    ):
        self.stream_id = stream_id

        wallet_private_key = os.getenv('ZEROG_WALLET_KEY')
        if not wallet_private_key:
            raise ValueError("ZEROG_WALLET_KEY environment variable is required")

        evm = EvmClient(
            rpc_url=rpc_url,
            private_key=wallet_private_key,
        )

        self._cached = CachedKvClient(
            kv_url=kv_url,
            indexer_url=indexer_url,
            evm_client=evm,
            flow_address=flow_address,
            max_queue_size=max_queue_size,
            max_cache_entries=max_cache_entries,
            upload_option=UploadOption(skip_tx=False),
            encryption_key=_ENCRYPTION_KEY,
        )

        # Atomic counter: ops staged since the last commit.
        self._pending_count = _AtomicInt()

        # Background commit thread
        self._stop_event = threading.Event()
        self._commit_thread = threading.Thread(
            target=self._commit_loop,
            name="zerog_commit",
            daemon=True,
        )
        self._commit_thread.start()

        # Per-instance operation log file under /tmp
        dt_str = datetime.now().strftime("%Y%m%d_%H%M%S")
        self._op_log_path = f"/tmp/log_EverMemOS_ZeroGKVStorage_{dt_str}.txt"
        self._op_log_lock = threading.Lock()
        self._op_log_file = open(self._op_log_path, 'w', encoding='utf-8')
        self._op_log_file.write(
            f"[{datetime.now().isoformat()}] ZeroGKVStorage initialized:"
            f" stream_id={stream_id}, kv_url={kv_url}\n"
        )
        self._op_log_file.flush()

        logger.info(
            f"‚úÖ ZeroGKVStorage initialized: stream_id={stream_id}, "
            f"kv_url={kv_url}, indexer_url={indexer_url}, "
            f"commit_interval={COMMIT_INTERVAL}s"
        )
        logger.info(f"üìÑ ZeroGKVStorage op log: {self._op_log_path}")

    # -------------------------------------------------------------------------
    # Internal: time-based commit loop
    # -------------------------------------------------------------------------

    def _commit_loop(self) -> None:
        """
        Dedicated background thread.
        Wakes up every COMMIT_INTERVAL seconds.
        If _pending_count > 0, calls cached.commit() (non-blocking) and resets
        the counter. If _pending_count == 0, skips the interval silently.
        """
        while not self._stop_event.wait(COMMIT_INTERVAL):
            pending = self._pending_count.get_and_reset()
            if not pending:
                continue

            try:
                self._cached.commit()
                logger.info(f"‚úÖ Commit triggered ({pending} pending ops)")
                self._write_op_log(f"commit triggered ({pending} pending ops)")
            except Exception as e:
                logger.error(f"‚ùå Commit failed: {e}", exc_info=True)

    # -------------------------------------------------------------------------
    # Internal: write a line to the per-instance operation log file
    # -------------------------------------------------------------------------

    def _write_op_log(self, msg: str) -> None:
        with self._op_log_lock:
            try:
                self._op_log_file.write(f"[{datetime.now().isoformat()}] {msg}\n")
                self._op_log_file.flush()
            except Exception:
                pass

    # -------------------------------------------------------------------------
    # Internal: stage a set/delete operation
    # -------------------------------------------------------------------------

    def _stage_operation(self, key: str, value_bytes: bytes) -> bool:
        """
        Call cached.set() then increment _pending_count.
        The commit thread will flush to the chain on the next interval.
        """
        key_bytes = key.encode('utf-8')
        self._cached.set(self.stream_id, key_bytes, value_bytes)
        self._pending_count.increment()
        return True

    # -------------------------------------------------------------------------
    # KVStorageInterface implementation
    # -------------------------------------------------------------------------

    async def get(self, key: str) -> Optional[str]:
        logger.info(f"get key={key}")
        self._write_op_log(f"get key={key}")
        try:
            key_bytes = key.encode('utf-8')
            value_bytes = self._cached.get_bytes(self.stream_id, key_bytes)
            if not value_bytes:
                self._write_op_log(f"get value=None")
                return None
            value = value_bytes.decode('utf-8')
            self._write_op_log(f"get value={value}")
            return value
        except Exception as e:
            logger.error(f"‚ùå Failed to get key {key}: {e}")
            return None

    async def put(self, key: str, value: str) -> bool:
        """Stage a put operation. Commit happens in the background thread."""
        logger.info(f"put key={key}")
        self._write_op_log(f"put key={key}")
        self._write_op_log(f"put value={value}")
        try:
            return self._stage_operation(key, value.encode('utf-8'))
        except Exception as e:
            logger.error(f"‚ùå Failed to put key {key}: {e}")
            return False

    async def delete(self, key: str) -> bool:
        """Stage a delete operation (empty bytes). Commit happens in the background thread."""
        logger.info(f"delete key={key}")
        self._write_op_log(f"delete key={key}")
        try:
            return self._stage_operation(key, b'')
        except Exception as e:
            logger.error(f"‚ùå Failed to delete key {key}: {e}")
            return False

    async def batch_get(self, keys: List[str]) -> Dict[str, str]:
        logger.info(f"batch_get keys={keys}")
        self._write_op_log(f"batch_get keys={keys}")
        if not keys:
            return {}

        result = {}
        try:
            for key in keys:
                key_bytes = key.encode('utf-8')
                value_bytes = self._cached.get_bytes(self.stream_id, key_bytes)
                if value_bytes:
                    result[key] = value_bytes.decode('utf-8')

            logger.info(f"‚úÖ Batch get {len(result)}/{len(keys)} keys")
            return result

        except Exception as e:
            logger.error(f"‚ùå Failed to batch get {len(keys)} keys: {e}")
            return {}

    async def batch_delete(self, keys: List[str]) -> int:
        """Stage delete for each key. Commit happens in the background thread."""
        logger.info(f"batch_delete keys={keys}")
        self._write_op_log(f"batch_delete keys={keys}")
        if not keys:
            return 0

        deleted = 0
        for key in keys:
            try:
                if self._stage_operation(key, b''):
                    deleted += 1
            except Exception as e:
                logger.error(f"‚ùå Failed to stage delete for key {key}: {e}")

        return deleted

    async def iterate_all(self) -> AsyncIterator[Tuple[str, str]]:
        """
        Iterate all key-value pairs using CachedKvClient's iterator.
        Empty/deleted entries (empty bytes) are skipped.
        """
        logger.info("iterate_all")
        try:
            iterator = self._cached._kv_client.new_iterator(self.stream_id)
            iterator.seek_to_first()

            total_count = 0
            skipped_count = 0

            while iterator.valid():
                key_bytes = iterator.key
                data_bytes = iterator.data

                key = key_bytes.decode('utf-8')

                if data_bytes and len(data_bytes) > 0:
                    value = data_bytes.decode('utf-8')
                    total_count += 1
                    yield (key, value)
                else:
                    skipped_count += 1

                iterator.next()

                if (total_count + skipped_count) % 1000 == 0 and (total_count + skipped_count) > 0:
                    logger.info(
                        f"üìä ZeroG iterate progress: {total_count} yielded, "
                        f"{skipped_count} skipped (empty/deleted)"
                    )

            logger.info(
                f"‚úÖ ZeroG iterate_all completed: {total_count} yielded, "
                f"{skipped_count} skipped"
            )

        except Exception as e:
            logger.error(f"‚ùå ZeroG iterate_all failed: {e}", exc_info=True)
            raise

    def close(self) -> None:
        """
        Stop the commit thread, flush any remaining pending ops, then
        release CachedKvClient resources.
        """
        self._stop_event.set()
        self._commit_thread.join(timeout=5)

        # CachedKvClient.close() will itself commit any remaining pending writes
        # and wait for all queued uploads to finish before shutting down the worker.
        try:
            self._cached.close()
            logger.info("‚úÖ ZeroGKVStorage closed")
        except Exception as e:
            logger.error(f"‚ùå Failed to close CachedKvClient: {e}")

        with self._op_log_lock:
            try:
                self._op_log_file.write(
                    f"[{datetime.now().isoformat()}] ZeroGKVStorage closed\n"
                )
                self._op_log_file.close()
            except Exception:
                pass


__all__ = ["ZeroGKVStorage"]
