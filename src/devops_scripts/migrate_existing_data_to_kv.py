#!/usr/bin/env python3
"""
è¿ç§»è„šæœ¬ï¼šå°†ç°æœ‰MongoDBæ•°æ®åŒæ­¥åˆ°KV-Storage

ç”¨é€”ï¼š
- ä¸ºåŒå­˜å‚¨å¯ç”¨å‰åˆ›å»ºçš„æ—§æ•°æ®è¡¥å……KVå­˜å‚¨
- è®©æ—§æ•°æ®ä¹Ÿèƒ½è¢«DualStorageQueryProxyæ­£ç¡®è¯»å–

ä½¿ç”¨æ–¹æ³•ï¼š
    uv run python src/bootstrap.py src/devops_scripts/migrate_existing_data_to_kv.py
"""

import sys
import asyncio
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# IMPORTANT: Must setup environment and DI BEFORE importing repositories
from common_utils.load_env import setup_environment
setup_environment(load_env_file_name=".env", check_env_var="MONGODB_HOST")

# Setup all (DI container, etc.)
from application_startup import setup_all
setup_all(load_entrypoints=False)

from core.di.utils import get_bean_by_type
from core.observation.logger import get_logger

logger = get_logger(__name__)


async def migrate_collection(
    collection_name: str,
    model_class,
    repository_class
):
    """
    è¿ç§»å•ä¸ªé›†åˆçš„æ•°æ®åˆ°KV-Storage

    Args:
        collection_name: é›†åˆåç§°ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
        model_class: Documentæ¨¡å‹ç±»
        repository_class: Repositoryç±»
    """
    print(f"\n{'='*80}")
    print(f"è¿ç§»é›†åˆ: {collection_name}")
    print(f"{'='*80}")

    from infra_layer.adapters.out.persistence.kv_storage.kv_storage_interface import (
        KVStorageInterface,
    )

    kv_storage = get_bean_by_type(KVStorageInterface)

    # ä½¿ç”¨PyMongoç›´æ¥æŸ¥è¯¢ï¼Œé¿å…PydanticéªŒè¯
    mongo_collection = model_class.get_pymongo_collection()
    cursor = mongo_collection.find({})

    total_docs = await mongo_collection.count_documents({})
    print(f"ğŸ“Š MongoDBä¸­å…±æœ‰ {total_docs} æ¡æ–‡æ¡£")

    if total_docs == 0:
        print(f"  â„¹ï¸  é›†åˆä¸ºç©ºï¼Œè·³è¿‡")
        return

    migrated_count = 0
    already_exists_count = 0
    failed_count = 0
    missing_required_fields_count = 0

    batch_size = 100
    processed = 0

    async for doc in cursor:
        processed += 1
        doc_id = str(doc['_id'])

        try:
            # æ£€æŸ¥KVä¸­æ˜¯å¦å·²å­˜åœ¨
            existing = await kv_storage.get(key=doc_id)
            if existing is not None:
                already_exists_count += 1
                if processed % batch_size == 0:
                    print(f"  è¿›åº¦: {processed}/{total_docs} (å·²å­˜åœ¨: {already_exists_count})")
                continue

            # æ£€æŸ¥æ˜¯å¦æœ‰å¿…éœ€å­—æ®µ
            # æ ¹æ®ä¸åŒçš„é›†åˆæ£€æŸ¥ä¸åŒçš„å­—æ®µ
            required_fields_check = True
            if collection_name == "episodic_memories":
                # summaryå’Œepisodeæ˜¯requiredå­—æ®µ
                if not doc.get('summary') or not doc.get('episode'):
                    required_fields_check = False
                    missing_required_fields_count += 1
            elif collection_name == "event_log_records":
                # atomic_factæ˜¯requiredå­—æ®µ
                if not doc.get('atomic_fact'):
                    required_fields_check = False
                    missing_required_fields_count += 1
            elif collection_name == "foresight_records":
                # contentæ˜¯requiredå­—æ®µ
                if not doc.get('content'):
                    required_fields_check = False
                    missing_required_fields_count += 1

            if not required_fields_check:
                # ç¼ºå°‘å¿…éœ€å­—æ®µï¼Œè·³è¿‡
                if processed % batch_size == 0:
                    print(f"  è¿›åº¦: {processed}/{total_docs} (ç¼ºå°‘å­—æ®µ: {missing_required_fields_count})")
                continue

            # å°†æ–‡æ¡£å­˜å…¥KV-Storage
            import json
            from bson import ObjectId
            from datetime import datetime

            def json_serializer(obj):
                """Custom JSON serializer for ObjectId and datetime"""
                if isinstance(obj, ObjectId):
                    return str(obj)
                elif isinstance(obj, datetime):
                    return obj.isoformat()
                raise TypeError(f"Type {type(obj)} not serializable")

            # æ·»åŠ idå­—æ®µï¼ˆä»_idè½¬æ¢ï¼‰
            doc['id'] = doc['_id']
            # ç§»é™¤_idï¼ˆé¿å…åºåˆ—åŒ–é—®é¢˜ï¼‰
            doc_copy = {k: v for k, v in doc.items() if k != '_id'}

            kv_value = json.dumps(doc_copy, default=json_serializer)
            await kv_storage.put(key=doc_id, value=kv_value)

            migrated_count += 1

            if processed % batch_size == 0:
                print(f"  è¿›åº¦: {processed}/{total_docs} (å·²è¿ç§»: {migrated_count})")

        except Exception as e:
            failed_count += 1
            logger.error(f"  âŒ è¿ç§»å¤±è´¥ {doc_id}: {e}")

    # æœ€ç»ˆç»Ÿè®¡
    print(f"\nğŸ“ˆ è¿ç§»ç»“æœ:")
    print(f"  âœ… æ–°è¿ç§»: {migrated_count}")
    print(f"  â„¹ï¸  å·²å­˜åœ¨: {already_exists_count}")
    print(f"  âš ï¸  ç¼ºå°‘å¿…éœ€å­—æ®µï¼ˆè·³è¿‡ï¼‰: {missing_required_fields_count}")
    print(f"  âŒ å¤±è´¥: {failed_count}")
    print(f"  ğŸ“Š æ€»è®¡: {total_docs}")


async def main():
    """ä¸»è¿ç§»æµç¨‹"""
    print("\n" + "ğŸ”„"*40)
    print("MongoDBæ•°æ®è¿ç§»åˆ°KV-Storage")
    print("ä¸ºæ—§æ•°æ®è¡¥å……åŒå­˜å‚¨æ”¯æŒ")
    print("ğŸ”„"*40)

    from infra_layer.adapters.out.persistence.document.memory.episodic_memory import (
        EpisodicMemory,
    )
    from infra_layer.adapters.out.persistence.document.memory.event_log_record import (
        EventLogRecord,
    )
    from infra_layer.adapters.out.persistence.document.memory.foresight_record import (
        ForesightRecord,
    )
    from infra_layer.adapters.out.persistence.document.memory.conversation_meta import (
        ConversationMeta,
    )
    from infra_layer.adapters.out.persistence.repository.episodic_memory_raw_repository import (
        EpisodicMemoryRawRepository,
    )
    from infra_layer.adapters.out.persistence.repository.event_log_record_raw_repository import (
        EventLogRecordRawRepository,
    )
    from infra_layer.adapters.out.persistence.repository.foresight_record_repository import (
        ForesightRecordRawRepository,
    )
    from infra_layer.adapters.out.persistence.repository.conversation_meta_raw_repository import (
        ConversationMetaRawRepository,
    )

    try:
        # è¿ç§»4ä¸ªä¸»è¦é›†åˆ
        await migrate_collection(
            "episodic_memories",
            EpisodicMemory,
            EpisodicMemoryRawRepository
        )

        await migrate_collection(
            "event_log_records",
            EventLogRecord,
            EventLogRecordRawRepository
        )

        await migrate_collection(
            "foresight_records",
            ForesightRecord,
            ForesightRecordRawRepository
        )

        await migrate_collection(
            "conversation_metas",
            ConversationMeta,
            ConversationMetaRawRepository
        )

        print("\n" + "="*80)
        print("âœ… è¿ç§»å®Œæˆï¼")
        print("="*80)
        print("\nç°åœ¨å¯ä»¥è¿è¡Œæµ‹è¯•è„šæœ¬éªŒè¯:")
        print("  uv run python src/bootstrap.py src/tests/test_dual_storage_mongodb_read.py")

    except Exception as e:
        logger.error(f"âŒ è¿ç§»è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}", exc_info=True)
        raise


if __name__ == "__main__":
    asyncio.run(main())
